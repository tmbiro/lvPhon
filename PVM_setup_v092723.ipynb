{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PVM Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import textdistance as td\n",
    "\n",
    "# Make sure you can see all output\n",
    "pd.options.display.max_rows = 4000\n",
    "# pd.options.display.max_columns = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>PID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Production</th>\n",
       "      <th>Prod_Word_Dur</th>\n",
       "      <th>Prod_Arpabet</th>\n",
       "      <th>Prod_Phon_Dur</th>\n",
       "      <th>NOTES</th>\n",
       "      <th>Word_ID</th>\n",
       "      <th>Session_ID</th>\n",
       "      <th>...</th>\n",
       "      <th>Height_Acc</th>\n",
       "      <th>Frontness_Acc</th>\n",
       "      <th>Tenseness_Acc</th>\n",
       "      <th>Roundness_Acc</th>\n",
       "      <th>wab1_aq</th>\n",
       "      <th>wab1_nwf_total</th>\n",
       "      <th>Session_Type</th>\n",
       "      <th>Improvement_Group</th>\n",
       "      <th>NWF_Improvement_Group</th>\n",
       "      <th>wabaq_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>0.295646</td>\n",
       "      <td>B</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>Article (ÃÂ) before word</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>0.295646</td>\n",
       "      <td>UH</td>\n",
       "      <td>0.163408</td>\n",
       "      <td>Article (ÃÂ) before word</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>0.295646</td>\n",
       "      <td>K</td>\n",
       "      <td>0.107875</td>\n",
       "      <td>Article (ÃÂ) before word</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>0.397365</td>\n",
       "      <td>B</td>\n",
       "      <td>0.014197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>0.397365</td>\n",
       "      <td>AO</td>\n",
       "      <td>0.211006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  PID Target Production  Prod_Word_Dur Prod_Arpabet  \\\n",
       "0           0   15   book     B UH K       0.295646            B   \n",
       "1           1   15   book     B UH K       0.295646           UH   \n",
       "2           2   15   book     B UH K       0.295646            K   \n",
       "3           3   15   ball     B AO L       0.397365            B   \n",
       "4           4   15   ball     B AO L       0.397365           AO   \n",
       "\n",
       "   Prod_Phon_Dur                       NOTES  Word_ID  Session_ID  ...  \\\n",
       "0       0.024363  Article (ÃÂ) before word      1.0         0.0  ...   \n",
       "1       0.163408  Article (ÃÂ) before word      1.0         0.0  ...   \n",
       "2       0.107875  Article (ÃÂ) before word      1.0         0.0  ...   \n",
       "3       0.014197                         NaN      2.0         0.0  ...   \n",
       "4       0.211006                         NaN      2.0         0.0  ...   \n",
       "\n",
       "   Height_Acc  Frontness_Acc Tenseness_Acc Roundness_Acc wab1_aq  \\\n",
       "0         1.0            1.0           1.0           1.0    67.8   \n",
       "1         1.0            1.0           1.0           1.0    67.8   \n",
       "2         1.0            1.0           1.0           1.0    67.8   \n",
       "3         1.0            1.0           1.0           1.0    67.8   \n",
       "4         1.0            1.0           1.0           1.0    67.8   \n",
       "\n",
       "   wab1_nwf_total Session_Type Improvement_Group  NWF_Improvement_Group  \\\n",
       "0             3.8     Baseline       No_Improved        NWF_No_Improved   \n",
       "1             3.8     Baseline       No_Improved        NWF_No_Improved   \n",
       "2             3.8     Baseline       No_Improved        NWF_No_Improved   \n",
       "3             3.8     Baseline       No_Improved        NWF_No_Improved   \n",
       "4             3.8     Baseline       No_Improved        NWF_No_Improved   \n",
       "\n",
       "   wabaq_start  \n",
       "0        61-70  \n",
       "1        61-70  \n",
       "2        61-70  \n",
       "3        61-70  \n",
       "4        61-70  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IPA_singles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Arpabet</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>H</th>\n",
       "      <td>h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R</th>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>W</th>\n",
       "      <td>w</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Y</th>\n",
       "      <td>j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CH</th>\n",
       "      <td>ʧ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DH</th>\n",
       "      <td>ð</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DX</th>\n",
       "      <td>ɾ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JH</th>\n",
       "      <td>ʤ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L</th>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M</th>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NG</th>\n",
       "      <td>ŋ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P</th>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SH</th>\n",
       "      <td>ʃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T</th>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TH</th>\n",
       "      <td>θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V</th>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Z</th>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZH</th>\n",
       "      <td>ʒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q</th>\n",
       "      <td>ʔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <td>ɑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AE</th>\n",
       "      <td>æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>ʌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AO</th>\n",
       "      <td>ɔ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AX</th>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EH</th>\n",
       "      <td>ɛ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EY</th>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IH</th>\n",
       "      <td>ɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IY</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UH</th>\n",
       "      <td>ʊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OW</th>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UW</th>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AW</th>\n",
       "      <td>μ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AY</th>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AXR</th>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ER</th>\n",
       "      <td>ɝ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OY</th>\n",
       "      <td>σ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        IPA_singles\n",
       "Arpabet            \n",
       "H                 h\n",
       "R                 r\n",
       "W                 w\n",
       "Y                 j\n",
       "B                 b\n",
       "CH                ʧ\n",
       "D                 d\n",
       "DH                ð\n",
       "DX                ɾ\n",
       "F                 f\n",
       "G                 g\n",
       "JH                ʤ\n",
       "K                 k\n",
       "L                 l\n",
       "M                 m\n",
       "N                 n\n",
       "NG                ŋ\n",
       "P                 p\n",
       "S                 s\n",
       "SH                ʃ\n",
       "T                 t\n",
       "TH                θ\n",
       "V                 v\n",
       "Z                 z\n",
       "ZH                ʒ\n",
       "Q                 ʔ\n",
       "AA                ɑ\n",
       "AE                æ\n",
       "AH                ʌ\n",
       "AO                ɔ\n",
       "AX                ə\n",
       "EH                ɛ\n",
       "EY                e\n",
       "IH                ɪ\n",
       "IY                i\n",
       "UH                ʊ\n",
       "OW                o\n",
       "UW                u\n",
       "AW                μ\n",
       "AY                ɐ\n",
       "AXR               ɚ\n",
       "ER                ɝ\n",
       "OY                σ"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Store filepath in a variable\n",
    "df = pd.read_csv(\"Resources/all_data_pvm_acc4.csv\")\n",
    "\n",
    "#Translate the ARPABET codes to IPA codes\n",
    "dictionary = (\n",
    "    pd.read_csv(\"Resources/dict.csv\")\n",
    "    .set_index(\"Arpabet\")\n",
    ")\n",
    "\n",
    "display(df.head(), dictionary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing IPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The IPA codes we have stored are corrupted, so we need to make them again\n",
    "df = df.drop(\n",
    "    [\n",
    "    'Unnamed: 0',\n",
    "    'NOTES',\n",
    "    'Prod_Word_Dur',\n",
    "    'Prod_Phon_Dur',\n",
    "    'Prod_Word_IPA',\n",
    "    'Prod_Phon_IPA',\n",
    "    'Target_Word_IPA',\n",
    "    'Target_Phon_IPA'\n",
    "    ], \n",
    "    axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B UH K', 'B AO L', 'N AY F', 'K AH P', 'S EY F T IY P IH N',\n",
       "       'H AE M AXR', 'T UW TH B R AX SH', 'AX R EY S AXR ', 'L AA K',\n",
       "       'P EH N S AX L', 'S K R UW D R AY V AXR', 'K IY',\n",
       "       'P EY P AXR K L IH P', 'W AA CH', 'K OW M', 'R AH B AXR B AE N D',\n",
       "       'S P UW N', 'T EY P', 'F AO R K', 'M AE CH AX Z'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that target words are correctly written\n",
    "df['Target_Arpabet'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace incorrect target words\n",
    "df['Target_Arpabet'] = (\n",
    "    df['Target_Arpabet']\n",
    "    .replace(\n",
    "        {\n",
    "        'AX R EY S AXR ':'AX R EY S AXR'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'UH', 'K', 'AO', 'L', 'N', 'AY', 'F', 'AH', 'P', 'S', 'EY',\n",
       "       'T', 'IY', 'IH', 'H', 'AE', 'M', 'AXR', 'UW', 'TH', 'R', 'AX',\n",
       "       'SH', 'AA', 'EH', 'D', 'V', 'W', 'CH', 'OW', 'Z'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check what each phoneme is being registered as\n",
    "results = (\n",
    "    # trans is a series, so use string accessor to split value strings\n",
    "    df[\"Target_Arpabet\"].str.split(\" \")\n",
    "    # turn each item in split string into own row maintaining index value\n",
    "    .explode()\n",
    ")\n",
    "\n",
    "results.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B UH K', 'B AO L', 'SH', 'N', 'N AY F', 'K AH P', 'S',\n",
       "       'S AY F T IY', 'H AE M AXR', 'T UW SH B OW N', 'T UW', 'B UH SH',\n",
       "       'T UH', 'T IY', 'T UW TH P IY S', 'T P IY', 'T IY S', 'P IY', 'P',\n",
       "       'IY', 'R AH B', 'R AH B AXR N', 'R AH B AXR', 'L AA K AXR',\n",
       "       'T EH M', 'T', 'P EH N S AX L', 'S T R UW', 'S T R',\n",
       "       'S T R UW DX OW', 'S K R UW', 'S K R UW CH', 'S K R UW S', 'K',\n",
       "       'ZH', 'K IY', 'T S', 'S IH M', 'P EY P AXR', 'W AA CH', 'OW',\n",
       "       'R AH B AXR L', 'R AH B AXR N AX Q', 'R AH', 'K AH', 'Q', 'S P UW',\n",
       "       'S P UH SH', 'S P', 'S B AH', 'S UW P', 'T EY', 'SH AO R', 'B AX',\n",
       "       'AY F', 'AY', 'K AO', 'K AH F', 'K AO Q', 'K AO F', 'K AH Q',\n",
       "       'S T EY Q', 'S T EY', 'S T AY', 'H', 'H AE', 'T IH TH', 'P EY S',\n",
       "       'B AA', 'P AH', 'B', 'B AH', 'L', 'L AA K', 'P EH N CH R',\n",
       "       'P EH N S IH', 'P EH N', 'P EH', 'P IH N', 'K OW', 'K AX',\n",
       "       'S T IH F', 'S P UW N', 'T AE', 'P AX', 'P IH', 'P T S', 'F AX',\n",
       "       'F', 'S EY F T IY', 'S AH', 'S S', 'R', 'T UW S', 'T UW TH',\n",
       "       'P EH N T', 'P EH N T AX L', 'P EH S', 'W AO', 'W AA', 'W AA Q',\n",
       "       'R OW', 'L EH Q', 'K AO F IY', 'S EY F S EY F T IY', 'S EY F',\n",
       "       'S S EY F T IY', 'S IY', 'K OW N', 'H AE T', 'B R AH SH',\n",
       "       'T UW TH B R AH SH', 'EH S', 'B IY', 'B AH S', 'B IY S',\n",
       "       'R EY S AXR', 'L AH K', 'JH EY', 'JH IY', 'S K R UW B AX',\n",
       "       'S K R UW B AY', 'S K R UW B IH T', 'S K R UW B', 'S IY OW',\n",
       "       'S IY OW EH N', 'H EH R', 'K OW T', 'K OW M', 'R OW P',\n",
       "       'R AH B AXR B AE N D', 'T R IY', 'K AX S AH M TH IH NG',\n",
       "       'S P UW P', 'S K UW P', 'B IY CH', 'T EY P', 'F UH T', 'F AO R K',\n",
       "       'S IH G AX R EH T', 'M EH T', 'M AE Q', 'M AE', 'M AE SH',\n",
       "       'M AE CH IH Z', 'H IY H AE', 'K AH R', 'D IY', 'EY', 'D R AY',\n",
       "       'D AO G', 'D AO', 'D IY OW Q AH R', 'T AX', 'H AE N D AX L',\n",
       "       'F AO R W EY', 'F AO R', 'D EY', 'B IH T', 'N EY L Z', 'N IY L Z',\n",
       "       'H AE M', 'T UW TH K IH T', 'S EY', 'T R UW TH', 'CH', 'B UW T S',\n",
       "       'T UW TH S', 'S IH T', 'S EH', 'IY R', 'R EY S', 'M AE S T AXR',\n",
       "       'S K R UW D R AY V AXR', 'P EY P AXR K L IH P', 'W AH CH',\n",
       "       'K OW Q', 'K AA Q', 'R AH B AX R', 'T EY K AX N', 'T EY K',\n",
       "       'M AE S', 'S M EH CH IH Z', 'S EY F T IY G AY K', 'S EH T',\n",
       "       'S EY F T IY P IH N', 'H AE B', 'H AE V', 'IH R EY S AXR',\n",
       "       'T UW TH W IH Z', 'T UW TH IH S', 'S UW', 'S K R UW JH AXR',\n",
       "       'S K UW T AXR', 'K IY Z', 'K AO L', 'K OW L', 'T AE K', 'K EY',\n",
       "       'H AE M AX R', 'T UW TH B R AX SH', 'AX R EY S AXR',\n",
       "       'M AE CH AX Z', 'K IY S', 'S UW S', 'IH', 'B AA L', 'K UH P',\n",
       "       'B R UH CH AXR T IY TH', 'B R UH SH T IY TH', 'B R UH SH',\n",
       "       'EH R EY S AXR', 'P EH N S L', 'S R UW D R OW V AXR D R AY V AXR',\n",
       "       'R UH B AXR B AE N D', 'T AE T', 'B OW T', 'T UW TH B EH SH',\n",
       "       'T UW TH B R UH SH', 'L EY D AXR', 'S UW N', 'M AE CH IH S',\n",
       "       'H AA R', 'D R AY V AXR', 'P EY P AXR K L IH', 'K K UH M',\n",
       "       'F AY AXR', 'F R AA G', 'AA R Y UW', 'K UH', 'S K UW D R AY V AXR',\n",
       "       'P EY P AXR D EY', 'W AA SH', 'R UH B AXR R UH B AXR B AE N D',\n",
       "       'F OW R K', 'M AE CH', 'M AE CH B UH K', 'D AA G',\n",
       "       'G UH D AA K AA R L', 'UH R EY S AXR', 'M UH K AE N IH K',\n",
       "       'P IH F', 'P EY P AXR K IH', 'K L IH P', 'K UH M',\n",
       "       'R UH B AXR B AE N T', 'M', 'B UH K B R UH K', 'B R UH K', 'N IH',\n",
       "       'M AE N AXR', 'AE M AXR', 'T UW TH B R UH K', 'EH L', 'L EY AXR',\n",
       "       'JH R AY V AXR', 'K AA M K AA M', 'R UH B AXR', 'S K AA CH',\n",
       "       'S K AA CH T EY', 'M AE UH CH', 'M AE CH IH', 'M AE CH IH T IY',\n",
       "       'M AE CH Y AE', 'R IY M OW T', 'IY R EY S', 'T AY S T IY K OW M',\n",
       "       'S AY F T IY P IH N', 'IY R EY S AXR', 'G EH DX IH N',\n",
       "       'K R UW D R AY V AXR', 'B AXR B AE N D', 'UW D R AY V AXR',\n",
       "       'AA P AH N', 'AXR H AE M AXR', 'T UW TH P EY S', 'W AO CH',\n",
       "       'T UW Q B R AH SH', 'P EY S T', 'T UW TH P EY S T', 'L AO K',\n",
       "       'S K', 'S K R UW B UW T', 'S K R UW D IY R', 'S K R UW D IY AX',\n",
       "       'R AX B AXR B AE N D', nan, 'M AE CH B AA K S', 'B AA B IY P IH N',\n",
       "       'S S K R UW D R AY V AXR', 'R AX B AXR B AE N', 'R AX B AXR',\n",
       "       'P EY S T AXR', 'CH AA R JH', 'S EY F T IY K L IH P',\n",
       "       'S EY F T IY P EH N'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check that productions are correctly written\n",
    "df['Production'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Production'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PID',\n",
       " 'Target',\n",
       " 'Production',\n",
       " 'Prod_Arpabet',\n",
       " 'Word_ID',\n",
       " 'Session_ID',\n",
       " 'Prod_Word_N',\n",
       " 'Prod_Phon_N',\n",
       " 'Code',\n",
       " 'Phon_Sess_Code',\n",
       " 'Word_Sess_Code',\n",
       " 'Prod_Last_Phon',\n",
       " 'Prod_Phoneme_ID',\n",
       " 'Prod_Prev_Phon',\n",
       " 'Prod_Next_Phon',\n",
       " 'Target_Arpabet',\n",
       " 'Target_N_Tot_Words',\n",
       " 'Target_N_Tot_Syllables',\n",
       " 'Target_N_Tot_Phonemes',\n",
       " 'Target_Phon_Arpabet',\n",
       " 'Target_Phoneme_ID',\n",
       " 'Target_Syll_Env',\n",
       " 'Target_Word_Pos',\n",
       " 'Syllable_NumID',\n",
       " 'Target_Word_NumID',\n",
       " 'Target_Con_Cluster',\n",
       " 'Target_Clust_ID',\n",
       " 'Target_Clus_Type',\n",
       " 'Target_Clust_Phon_Pos',\n",
       " 'Target_Clust_Phon_Env',\n",
       " 'Target_Prev_Phon',\n",
       " 'Target_Next_Phon',\n",
       " 'Prod_syllabic',\n",
       " 'Prod_consonantal',\n",
       " 'Prod_sonorant',\n",
       " 'Prod_continuant',\n",
       " 'Prod_delayed release',\n",
       " 'Prod_approximant',\n",
       " 'Prod_tap',\n",
       " 'Prod_nasal',\n",
       " 'Prod_voice',\n",
       " 'Prod_spread gl',\n",
       " 'Prod_constr gl',\n",
       " 'Prod_labial',\n",
       " 'Prod_round',\n",
       " 'Prod_labiodental',\n",
       " 'Prod_coronal',\n",
       " 'Prod_anterior',\n",
       " 'Prod_distributed',\n",
       " 'Prod_strident',\n",
       " 'Prod_lateral',\n",
       " 'Prod_dorsal',\n",
       " 'Prod_high',\n",
       " 'Prod_low',\n",
       " 'Prod_front',\n",
       " 'Prod_back',\n",
       " 'Prod_tense',\n",
       " 'Prod_lax',\n",
       " 'Prod_vowel',\n",
       " 'Prod_consonant',\n",
       " 'Prod_diphthong',\n",
       " 'Prod_monophthong',\n",
       " 'Prod_velar',\n",
       " 'Prod_alveolar',\n",
       " 'Prod_post-alveolar',\n",
       " 'Prod_dental',\n",
       " 'Prod_palatal',\n",
       " 'Prod_glottal',\n",
       " 'Prod_stop',\n",
       " 'Prod_fricative',\n",
       " 'Prod_affricate',\n",
       " 'Prod_glide',\n",
       " 'Prod_Place',\n",
       " 'Prod_Manner',\n",
       " 'Prod_Place_N',\n",
       " 'Prod_Manner_N',\n",
       " 'Prod_Height',\n",
       " 'Prod_Frontness',\n",
       " 'Prod_Height_N',\n",
       " 'Prod_Frontness_N',\n",
       " 'Target_syllabic',\n",
       " 'Target_consonantal',\n",
       " 'Target_sonorant',\n",
       " 'Target_continuant',\n",
       " 'Target_delayed release',\n",
       " 'Target_approximant',\n",
       " 'Target_tap',\n",
       " 'Target_nasal',\n",
       " 'Target_voice',\n",
       " 'Target_spread gl',\n",
       " 'Target_constr gl',\n",
       " 'Target_labial',\n",
       " 'Target_round',\n",
       " 'Target_labiodental',\n",
       " 'Target_coronal',\n",
       " 'Target_anterior',\n",
       " 'Target_distributed',\n",
       " 'Target_strident',\n",
       " 'Target_lateral',\n",
       " 'Target_dorsal',\n",
       " 'Target_high',\n",
       " 'Target_low',\n",
       " 'Target_front',\n",
       " 'Target_back',\n",
       " 'Target_tense',\n",
       " 'Target_lax',\n",
       " 'Target_vowel',\n",
       " 'Target_consonant',\n",
       " 'Target_diphthong',\n",
       " 'Target_monophthong',\n",
       " 'Target_velar',\n",
       " 'Target_alveolar',\n",
       " 'Target_post-alveolar',\n",
       " 'Target_dental',\n",
       " 'Target_palatal',\n",
       " 'Target_glottal',\n",
       " 'Target_stop',\n",
       " 'Target_fricative',\n",
       " 'Target_affricate',\n",
       " 'Target_glide',\n",
       " 'Target_Place',\n",
       " 'Target_Manner',\n",
       " 'Target_Place_N',\n",
       " 'Target_Manner_N',\n",
       " 'Target_Height',\n",
       " 'Target_Frontness',\n",
       " 'Target_Height_N',\n",
       " 'Target_Frontness_N',\n",
       " 'Phon_Acc',\n",
       " 'Voicing_Acc',\n",
       " 'Place_Acc',\n",
       " 'Manner_Acc',\n",
       " 'Height_Acc',\n",
       " 'Frontness_Acc',\n",
       " 'Tenseness_Acc',\n",
       " 'Roundness_Acc',\n",
       " 'wab1_aq',\n",
       " 'wab1_nwf_total',\n",
       " 'Session_Type',\n",
       " 'Improvement_Group',\n",
       " 'NWF_Improvement_Group',\n",
       " 'wabaq_start',\n",
       " 'Target_Word_IPA']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Target_Word_IPA\"] = (\n",
    "    # The production column is a series, so use string accessor to split value strings\n",
    "    df[\"Target_Arpabet\"].str.split(\" \")\n",
    "    # turn each item in split string into own row maintaining index value\n",
    "    .explode()\n",
    "    # perform the lookup in the dictionary of each individual value\n",
    "    .apply(lambda v: dictionary.loc[v])\n",
    "    # group them by the original index\n",
    "    .groupby(level=0)\n",
    "    # \"sum\" them, which for string, concatonates them without any spaces\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "df.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Production</th>\n",
       "      <th>Prod_Arpabet</th>\n",
       "      <th>Word_ID</th>\n",
       "      <th>Session_ID</th>\n",
       "      <th>Prod_Word_N</th>\n",
       "      <th>Prod_Phon_N</th>\n",
       "      <th>Code</th>\n",
       "      <th>Phon_Sess_Code</th>\n",
       "      <th>...</th>\n",
       "      <th>Tenseness_Acc</th>\n",
       "      <th>Roundness_Acc</th>\n",
       "      <th>wab1_aq</th>\n",
       "      <th>wab1_nwf_total</th>\n",
       "      <th>Session_Type</th>\n",
       "      <th>Improvement_Group</th>\n",
       "      <th>NWF_Improvement_Group</th>\n",
       "      <th>wabaq_start</th>\n",
       "      <th>Target_Word_IPA</th>\n",
       "      <th>Prod_Word_IPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_1</td>\n",
       "      <td>15_0_1_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>UH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>15_0_1_2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>K</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1_3</td>\n",
       "      <td>15_0_1_3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2_1</td>\n",
       "      <td>15_0_2_1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>bɔl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>AO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2_2</td>\n",
       "      <td>15_0_2_2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>67.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>bɔl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 144 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID Target Production Prod_Arpabet  Word_ID  Session_ID  Prod_Word_N  \\\n",
       "0   15   book     B UH K            B      1.0         0.0          1.0   \n",
       "1   15   book     B UH K           UH      1.0         0.0          1.0   \n",
       "2   15   book     B UH K            K      1.0         0.0          1.0   \n",
       "3   15   ball     B AO L            B      2.0         0.0          2.0   \n",
       "4   15   ball     B AO L           AO      2.0         0.0          2.0   \n",
       "\n",
       "   Prod_Phon_N Code Phon_Sess_Code  ... Tenseness_Acc  Roundness_Acc  wab1_aq  \\\n",
       "0          1.0  1_1       15_0_1_1  ...           1.0            1.0     67.8   \n",
       "1          2.0  1_2       15_0_1_2  ...           1.0            1.0     67.8   \n",
       "2          3.0  1_3       15_0_1_3  ...           1.0            1.0     67.8   \n",
       "3          1.0  2_1       15_0_2_1  ...           1.0            1.0     67.8   \n",
       "4          2.0  2_2       15_0_2_2  ...           1.0            1.0     67.8   \n",
       "\n",
       "   wab1_nwf_total  Session_Type Improvement_Group  NWF_Improvement_Group  \\\n",
       "0             3.8      Baseline       No_Improved        NWF_No_Improved   \n",
       "1             3.8      Baseline       No_Improved        NWF_No_Improved   \n",
       "2             3.8      Baseline       No_Improved        NWF_No_Improved   \n",
       "3             3.8      Baseline       No_Improved        NWF_No_Improved   \n",
       "4             3.8      Baseline       No_Improved        NWF_No_Improved   \n",
       "\n",
       "   wabaq_start  Target_Word_IPA Prod_Word_IPA  \n",
       "0        61-70              bʊk           bʊk  \n",
       "1        61-70              bʊk           bʊk  \n",
       "2        61-70              bʊk           bʊk  \n",
       "3        61-70              bɔl           bɔl  \n",
       "4        61-70              bɔl           bɔl  \n",
       "\n",
       "[5 rows x 144 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Prod_Word_IPA\"] = (\n",
    "    # The production column is a series, so use string accessor to split value strings\n",
    "    df[\"Production\"].str.split(\" \")\n",
    "    # turn each item in split string into own row maintaining index value\n",
    "    .explode()\n",
    "    # perform the lookup in the dictionary of each individual value\n",
    "    .apply(lambda v: dictionary.loc[v])\n",
    "    # group them by the original index\n",
    "    .groupby(level=0)\n",
    "    # \"sum\" them, which for string, concatonates them without any spaces\n",
    "    .sum()\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get number of phonemes for each production\n",
    "df['Prod_N_Tot_Phonemes'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x:\n",
    "        len(x['Prod_Word_IPA']),\n",
    "        axis=1\n",
    "    )\n",
    ")\n",
    "\n",
    "#Get number of phonemes for each target\n",
    "df['Target_N_Tot_Phonemes'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x:\n",
    "        len(x['Target_Word_IPA']),\n",
    "        axis=1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace incorrectly coded words\n",
    "df['Prod_Word_IPA'] = (\n",
    "    df['Prod_Word_IPA']\n",
    "    .replace(\n",
    "        {\n",
    "        'i':'ə', \n",
    "        'ir':'ər', \n",
    "        'ɪ':'ə', \n",
    "        'ɛresɚ':'əresɚ',\n",
    "        'ires':'əresɚ',\n",
    "        'ɪresɚ':'əresɚ', \n",
    "        'iresɚ':'əresɚ'\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import phonetic feature identifies\n",
    "phon_dist_features = (\n",
    "    pd.read_csv(\"Resources/phon_dist_features.csv\")\n",
    ")\n",
    "phon_dist_features = phon_dist_features.dropna()\n",
    "phon_dist_features['Phoneme_ID'] = phon_dist_features['Phoneme_ID'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target_Phoneme_IPA</th>\n",
       "      <th>Target_Phoneme_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ʧ</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ð</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ɾ</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>g</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ʤ</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>k</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>l</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>m</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>n</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ŋ</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>p</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>s</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ʃ</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>t</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>θ</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>v</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>z</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ʒ</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ʔ</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ɑ</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>æ</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ʌ</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ɔ</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ə</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ɛ</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>e</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ɪ</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>i</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ʊ</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>o</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>u</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>μ</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ɐ</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ɚ</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ɝ</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>σ</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>*</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Target_Phoneme_IPA  Target_Phoneme_ID\n",
       "0                   h                  1\n",
       "1                   r                  2\n",
       "2                   w                  3\n",
       "3                   j                  4\n",
       "4                   b                  5\n",
       "5                   ʧ                  6\n",
       "6                   d                  7\n",
       "7                   ð                  8\n",
       "8                   ɾ                  9\n",
       "9                   f                 10\n",
       "10                  g                 11\n",
       "11                  ʤ                 12\n",
       "12                  k                 13\n",
       "13                  l                 14\n",
       "14                  m                 15\n",
       "15                  n                 16\n",
       "16                  ŋ                 17\n",
       "17                  p                 18\n",
       "18                  s                 19\n",
       "19                  ʃ                 20\n",
       "20                  t                 21\n",
       "21                  θ                 22\n",
       "22                  v                 23\n",
       "23                  z                 24\n",
       "24                  ʒ                 25\n",
       "25                  ʔ                 26\n",
       "26                  ɑ                 27\n",
       "27                  æ                 28\n",
       "28                  ʌ                 29\n",
       "29                  ɔ                 30\n",
       "30                  ə                 31\n",
       "31                  ɛ                 32\n",
       "32                  e                 33\n",
       "33                  ɪ                 34\n",
       "34                  i                 35\n",
       "35                  ʊ                 36\n",
       "36                  o                 37\n",
       "37                  u                 38\n",
       "38                  μ                 39\n",
       "39                  ɐ                 40\n",
       "40                  ɚ                 41\n",
       "41                  ɝ                 42\n",
       "42                  σ                 43\n",
       "43                  *                 44"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a dictionary for phoneme ID number\n",
    "\n",
    "Prod_phon_ID = phon_dist_features[['IPA_singles','Phoneme_ID']].copy()\n",
    "Target_phon_ID = phon_dist_features[['IPA_singles','Phoneme_ID']].copy()\n",
    "\n",
    "\n",
    "# Creat dictionary for Prod_Phoneme_ID\n",
    "Prod_phon_ID.rename(\n",
    "    columns={\n",
    "       'IPA_singles':'Prod_Phoneme_IPA', \n",
    "       'Phoneme_ID':'Prod_Phoneme_ID'\n",
    "       }, inplace=True)\n",
    "\n",
    "Target_phon_ID.rename(\n",
    "    columns={\n",
    "       'IPA_singles':'Target_Phoneme_IPA', \n",
    "       'Phoneme_ID':'Target_Phoneme_ID'\n",
    "       }, inplace=True)\n",
    "\n",
    "Prod_phon_ID\n",
    "Target_phon_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PID</th>\n",
       "      <th>Target</th>\n",
       "      <th>Production</th>\n",
       "      <th>Prod_Arpabet</th>\n",
       "      <th>Word_ID</th>\n",
       "      <th>Session_ID</th>\n",
       "      <th>Prod_Word_N</th>\n",
       "      <th>Prod_Phon_N</th>\n",
       "      <th>Code</th>\n",
       "      <th>Phon_Sess_Code</th>\n",
       "      <th>...</th>\n",
       "      <th>wab1_nwf_total</th>\n",
       "      <th>Session_Type</th>\n",
       "      <th>Improvement_Group</th>\n",
       "      <th>NWF_Improvement_Group</th>\n",
       "      <th>wabaq_start</th>\n",
       "      <th>Target_Word_IPA</th>\n",
       "      <th>Prod_Word_IPA</th>\n",
       "      <th>Prod_N_Tot_Phonemes</th>\n",
       "      <th>Prod_Phoneme_IPA</th>\n",
       "      <th>Target_Phoneme_IPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>B</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1_1</td>\n",
       "      <td>15_0_1_1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>UH</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1_2</td>\n",
       "      <td>15_0_1_2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>3</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>ʊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>book</td>\n",
       "      <td>B UH K</td>\n",
       "      <td>K</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1_3</td>\n",
       "      <td>15_0_1_3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>3</td>\n",
       "      <td>k</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>B</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2_1</td>\n",
       "      <td>15_0_2_1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>3</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>ball</td>\n",
       "      <td>B AO L</td>\n",
       "      <td>AO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2_2</td>\n",
       "      <td>15_0_2_2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.8</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>No_Improved</td>\n",
       "      <td>NWF_No_Improved</td>\n",
       "      <td>61-70</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>bɔl</td>\n",
       "      <td>3</td>\n",
       "      <td>ɔ</td>\n",
       "      <td>ɔ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PID Target Production Prod_Arpabet  Word_ID  Session_ID  Prod_Word_N  \\\n",
       "0   15   book     B UH K            B      1.0         0.0          1.0   \n",
       "1   15   book     B UH K           UH      1.0         0.0          1.0   \n",
       "2   15   book     B UH K            K      1.0         0.0          1.0   \n",
       "3   15   ball     B AO L            B      2.0         0.0          2.0   \n",
       "4   15   ball     B AO L           AO      2.0         0.0          2.0   \n",
       "\n",
       "   Prod_Phon_N Code Phon_Sess_Code  ... wab1_nwf_total  Session_Type  \\\n",
       "0          1.0  1_1       15_0_1_1  ...            3.8      Baseline   \n",
       "1          2.0  1_2       15_0_1_2  ...            3.8      Baseline   \n",
       "2          3.0  1_3       15_0_1_3  ...            3.8      Baseline   \n",
       "3          1.0  2_1       15_0_2_1  ...            3.8      Baseline   \n",
       "4          2.0  2_2       15_0_2_2  ...            3.8      Baseline   \n",
       "\n",
       "   Improvement_Group  NWF_Improvement_Group  wabaq_start Target_Word_IPA  \\\n",
       "0        No_Improved        NWF_No_Improved        61-70             bʊk   \n",
       "1        No_Improved        NWF_No_Improved        61-70             bʊk   \n",
       "2        No_Improved        NWF_No_Improved        61-70             bʊk   \n",
       "3        No_Improved        NWF_No_Improved        61-70             bɔl   \n",
       "4        No_Improved        NWF_No_Improved        61-70             bɔl   \n",
       "\n",
       "   Prod_Word_IPA  Prod_N_Tot_Phonemes  Prod_Phoneme_IPA Target_Phoneme_IPA  \n",
       "0            bʊk                    3                 b                  b  \n",
       "1            bʊk                    3                 ʊ                  ʊ  \n",
       "2            bʊk                    3                 k                  k  \n",
       "3            bɔl                    3                 b                  b  \n",
       "4            bɔl                    3                 ɔ                  ɔ  \n",
       "\n",
       "[5 rows x 147 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with original dataset\n",
    "df = df.merge(Prod_phon_ID, on='Prod_Phoneme_ID', how='left').merge(Target_phon_ID, on='Target_Phoneme_ID', how='left')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PID',\n",
       " 'Target',\n",
       " 'Production',\n",
       " 'Prod_Arpabet',\n",
       " 'Word_ID',\n",
       " 'Session_ID',\n",
       " 'Prod_Word_N',\n",
       " 'Prod_Phon_N',\n",
       " 'Code',\n",
       " 'Phon_Sess_Code',\n",
       " 'Word_Sess_Code',\n",
       " 'Prod_Last_Phon',\n",
       " 'Prod_Phoneme_ID',\n",
       " 'Prod_Prev_Phon',\n",
       " 'Prod_Next_Phon',\n",
       " 'Target_Arpabet',\n",
       " 'Target_N_Tot_Words',\n",
       " 'Target_N_Tot_Syllables',\n",
       " 'Target_N_Tot_Phonemes',\n",
       " 'Target_Phon_Arpabet',\n",
       " 'Target_Phoneme_ID',\n",
       " 'Target_Syll_Env',\n",
       " 'Target_Word_Pos',\n",
       " 'Syllable_NumID',\n",
       " 'Target_Word_NumID',\n",
       " 'Target_Con_Cluster',\n",
       " 'Target_Clust_ID',\n",
       " 'Target_Clus_Type',\n",
       " 'Target_Clust_Phon_Pos',\n",
       " 'Target_Clust_Phon_Env',\n",
       " 'Target_Prev_Phon',\n",
       " 'Target_Next_Phon',\n",
       " 'Prod_syllabic',\n",
       " 'Prod_consonantal',\n",
       " 'Prod_sonorant',\n",
       " 'Prod_continuant',\n",
       " 'Prod_delayed release',\n",
       " 'Prod_approximant',\n",
       " 'Prod_tap',\n",
       " 'Prod_nasal',\n",
       " 'Prod_voice',\n",
       " 'Prod_spread gl',\n",
       " 'Prod_constr gl',\n",
       " 'Prod_labial',\n",
       " 'Prod_round',\n",
       " 'Prod_labiodental',\n",
       " 'Prod_coronal',\n",
       " 'Prod_anterior',\n",
       " 'Prod_distributed',\n",
       " 'Prod_strident',\n",
       " 'Prod_lateral',\n",
       " 'Prod_dorsal',\n",
       " 'Prod_high',\n",
       " 'Prod_low',\n",
       " 'Prod_front',\n",
       " 'Prod_back',\n",
       " 'Prod_tense',\n",
       " 'Prod_lax',\n",
       " 'Prod_vowel',\n",
       " 'Prod_consonant',\n",
       " 'Prod_diphthong',\n",
       " 'Prod_monophthong',\n",
       " 'Prod_velar',\n",
       " 'Prod_alveolar',\n",
       " 'Prod_post-alveolar',\n",
       " 'Prod_dental',\n",
       " 'Prod_palatal',\n",
       " 'Prod_glottal',\n",
       " 'Prod_stop',\n",
       " 'Prod_fricative',\n",
       " 'Prod_affricate',\n",
       " 'Prod_glide',\n",
       " 'Prod_Place',\n",
       " 'Prod_Manner',\n",
       " 'Prod_Place_N',\n",
       " 'Prod_Manner_N',\n",
       " 'Prod_Height',\n",
       " 'Prod_Frontness',\n",
       " 'Prod_Height_N',\n",
       " 'Prod_Frontness_N',\n",
       " 'Target_syllabic',\n",
       " 'Target_consonantal',\n",
       " 'Target_sonorant',\n",
       " 'Target_continuant',\n",
       " 'Target_delayed release',\n",
       " 'Target_approximant',\n",
       " 'Target_tap',\n",
       " 'Target_nasal',\n",
       " 'Target_voice',\n",
       " 'Target_spread gl',\n",
       " 'Target_constr gl',\n",
       " 'Target_labial',\n",
       " 'Target_round',\n",
       " 'Target_labiodental',\n",
       " 'Target_coronal',\n",
       " 'Target_anterior',\n",
       " 'Target_distributed',\n",
       " 'Target_strident',\n",
       " 'Target_lateral',\n",
       " 'Target_dorsal',\n",
       " 'Target_high',\n",
       " 'Target_low',\n",
       " 'Target_front',\n",
       " 'Target_back',\n",
       " 'Target_tense',\n",
       " 'Target_lax',\n",
       " 'Target_vowel',\n",
       " 'Target_consonant',\n",
       " 'Target_diphthong',\n",
       " 'Target_monophthong',\n",
       " 'Target_velar',\n",
       " 'Target_alveolar',\n",
       " 'Target_post-alveolar',\n",
       " 'Target_dental',\n",
       " 'Target_palatal',\n",
       " 'Target_glottal',\n",
       " 'Target_stop',\n",
       " 'Target_fricative',\n",
       " 'Target_affricate',\n",
       " 'Target_glide',\n",
       " 'Target_Place',\n",
       " 'Target_Manner',\n",
       " 'Target_Place_N',\n",
       " 'Target_Manner_N',\n",
       " 'Target_Height',\n",
       " 'Target_Frontness',\n",
       " 'Target_Height_N',\n",
       " 'Target_Frontness_N',\n",
       " 'Phon_Acc',\n",
       " 'Voicing_Acc',\n",
       " 'Place_Acc',\n",
       " 'Manner_Acc',\n",
       " 'Height_Acc',\n",
       " 'Frontness_Acc',\n",
       " 'Tenseness_Acc',\n",
       " 'Roundness_Acc',\n",
       " 'wab1_aq',\n",
       " 'wab1_nwf_total',\n",
       " 'Session_Type',\n",
       " 'Improvement_Group',\n",
       " 'NWF_Improvement_Group',\n",
       " 'wabaq_start',\n",
       " 'Target_Word_IPA',\n",
       " 'Prod_Word_IPA',\n",
       " 'Prod_N_Tot_Phonemes',\n",
       " 'Prod_Phoneme_IPA',\n",
       " 'Target_Phoneme_IPA']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out columns\n",
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a shortened dataset\n",
    "dfShort = df.drop(\n",
    "    [\n",
    "    'Production',\n",
    "    'Prod_Arpabet',\n",
    "    'Code',\n",
    "    'Prod_Last_Phon',\n",
    "    'Prod_Prev_Phon',\n",
    "    'Prod_Next_Phon',\n",
    "    'Target_Arpabet',\n",
    "    'Target_Phon_Arpabet',\n",
    "    'Target_Prev_Phon',\n",
    "    'Target_Next_Phon',\n",
    "    'Target_Clus_Type',\n",
    "    'Target_Clust_Phon_Pos',\n",
    "    'Target_Clust_Phon_Env',\n",
    "    'Improvement_Group',\n",
    "    'NWF_Improvement_Group'\n",
    "    ], \n",
    "    axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PID',\n",
       " 'Target',\n",
       " 'Word_ID',\n",
       " 'Session_ID',\n",
       " 'Prod_Word_N',\n",
       " 'Prod_Phon_N',\n",
       " 'Phon_Sess_Code',\n",
       " 'Word_Sess_Code',\n",
       " 'Prod_Phoneme_ID',\n",
       " 'Target_N_Tot_Words',\n",
       " 'Target_N_Tot_Syllables',\n",
       " 'Target_N_Tot_Phonemes',\n",
       " 'Target_Phoneme_ID',\n",
       " 'Target_Syll_Env',\n",
       " 'Target_Word_Pos',\n",
       " 'Syllable_NumID',\n",
       " 'Target_Word_NumID',\n",
       " 'Target_Con_Cluster',\n",
       " 'Target_Clust_ID',\n",
       " 'Target_Clus_Type',\n",
       " 'Target_Clust_Phon_Pos',\n",
       " 'Target_Clust_Phon_Env',\n",
       " 'Prod_syllabic',\n",
       " 'Prod_consonantal',\n",
       " 'Prod_sonorant',\n",
       " 'Prod_continuant',\n",
       " 'Prod_delayed release',\n",
       " 'Prod_approximant',\n",
       " 'Prod_tap',\n",
       " 'Prod_nasal',\n",
       " 'Prod_voice',\n",
       " 'Prod_spread gl',\n",
       " 'Prod_constr gl',\n",
       " 'Prod_labial',\n",
       " 'Prod_round',\n",
       " 'Prod_labiodental',\n",
       " 'Prod_coronal',\n",
       " 'Prod_anterior',\n",
       " 'Prod_distributed',\n",
       " 'Prod_strident',\n",
       " 'Prod_lateral',\n",
       " 'Prod_dorsal',\n",
       " 'Prod_high',\n",
       " 'Prod_low',\n",
       " 'Prod_front',\n",
       " 'Prod_back',\n",
       " 'Prod_tense',\n",
       " 'Prod_lax',\n",
       " 'Prod_vowel',\n",
       " 'Prod_consonant',\n",
       " 'Prod_diphthong',\n",
       " 'Prod_monophthong',\n",
       " 'Prod_velar',\n",
       " 'Prod_alveolar',\n",
       " 'Prod_post-alveolar',\n",
       " 'Prod_dental',\n",
       " 'Prod_palatal',\n",
       " 'Prod_glottal',\n",
       " 'Prod_stop',\n",
       " 'Prod_fricative',\n",
       " 'Prod_affricate',\n",
       " 'Prod_glide',\n",
       " 'Prod_Place',\n",
       " 'Prod_Manner',\n",
       " 'Prod_Place_N',\n",
       " 'Prod_Manner_N',\n",
       " 'Prod_Height',\n",
       " 'Prod_Frontness',\n",
       " 'Prod_Height_N',\n",
       " 'Prod_Frontness_N',\n",
       " 'Target_syllabic',\n",
       " 'Target_consonantal',\n",
       " 'Target_sonorant',\n",
       " 'Target_continuant',\n",
       " 'Target_delayed release',\n",
       " 'Target_approximant',\n",
       " 'Target_tap',\n",
       " 'Target_nasal',\n",
       " 'Target_voice',\n",
       " 'Target_spread gl',\n",
       " 'Target_constr gl',\n",
       " 'Target_labial',\n",
       " 'Target_round',\n",
       " 'Target_labiodental',\n",
       " 'Target_coronal',\n",
       " 'Target_anterior',\n",
       " 'Target_distributed',\n",
       " 'Target_strident',\n",
       " 'Target_lateral',\n",
       " 'Target_dorsal',\n",
       " 'Target_high',\n",
       " 'Target_low',\n",
       " 'Target_front',\n",
       " 'Target_back',\n",
       " 'Target_tense',\n",
       " 'Target_lax',\n",
       " 'Target_vowel',\n",
       " 'Target_consonant',\n",
       " 'Target_diphthong',\n",
       " 'Target_monophthong',\n",
       " 'Target_velar',\n",
       " 'Target_alveolar',\n",
       " 'Target_post-alveolar',\n",
       " 'Target_dental',\n",
       " 'Target_palatal',\n",
       " 'Target_glottal',\n",
       " 'Target_stop',\n",
       " 'Target_fricative',\n",
       " 'Target_affricate',\n",
       " 'Target_glide',\n",
       " 'Target_Place',\n",
       " 'Target_Manner',\n",
       " 'Target_Place_N',\n",
       " 'Target_Manner_N',\n",
       " 'Target_Height',\n",
       " 'Target_Frontness',\n",
       " 'Target_Height_N',\n",
       " 'Target_Frontness_N',\n",
       " 'Phon_Acc',\n",
       " 'Voicing_Acc',\n",
       " 'Place_Acc',\n",
       " 'Manner_Acc',\n",
       " 'Height_Acc',\n",
       " 'Frontness_Acc',\n",
       " 'Tenseness_Acc',\n",
       " 'Roundness_Acc',\n",
       " 'wab1_aq',\n",
       " 'wab1_nwf_total',\n",
       " 'Session_Type',\n",
       " 'wabaq_start',\n",
       " 'Target_Word_IPA',\n",
       " 'Prod_Word_IPA',\n",
       " 'Prod_N_Tot_Phonemes',\n",
       " 'Prod_Phoneme_IPA',\n",
       " 'Target_Phoneme_IPA']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfShort.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PID': {844: 1, 845: 1, 846: 1, 847: 1},\n",
       " 'Target': {844: 'spoon', 845: 'spoon', 846: 'spoon', 847: 'spoon'},\n",
       " 'Word_ID': {844: 17.0, 845: 17.0, 846: 17.0, 847: 17.0},\n",
       " 'Session_ID': {844: 0.0, 845: 0.0, 846: 0.0, 847: 0.0},\n",
       " 'Prod_Word_N': {844: 86.0, 845: 86.0, 846: 86.0, 847: 86.0},\n",
       " 'Prod_Phon_N': {844: 1.0, 845: 2.0, 846: 3.0, 847: 4.0},\n",
       " 'Phon_Sess_Code': {844: '1_0_86_1',\n",
       "  845: '1_0_86_2',\n",
       "  846: '1_0_86_3',\n",
       "  847: '1_0_86_4'},\n",
       " 'Word_Sess_Code': {844: '1_0_86',\n",
       "  845: '1_0_86',\n",
       "  846: '1_0_86',\n",
       "  847: '1_0_86'},\n",
       " 'Prod_Phoneme_ID': {844: 19.0, 845: 18.0, 846: 38.0, 847: 18.0},\n",
       " 'Target_N_Tot_Words': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_N_Tot_Syllables': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_N_Tot_Phonemes': {844: 4, 845: 4, 846: 4, 847: 4},\n",
       " 'Target_Phoneme_ID': {844: 19.0, 845: 18.0, 846: 38.0, 847: 16.0},\n",
       " 'Target_Syll_Env': {844: '#_V', 845: '#_V', 846: 'C_C', 847: 'V_#'},\n",
       " 'Target_Word_Pos': {844: '#_V', 845: 'C_V', 846: 'C_C', 847: 'V_#'},\n",
       " 'Syllable_NumID': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_Word_NumID': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_Con_Cluster': {844: 1.0, 845: 1.0, 846: 0.0, 847: 0.0},\n",
       " 'Target_Clust_ID': {844: 'sp', 845: 'sp', 846: nan, 847: nan},\n",
       " 'Prod_syllabic': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_consonantal': {844: 1.0, 845: 1.0, 846: -1.0, 847: 1.0},\n",
       " 'Prod_sonorant': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_continuant': {844: 1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_delayed release': {844: 1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_approximant': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_tap': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_nasal': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_voice': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_spread gl': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_constr gl': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_labial': {844: -1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Prod_round': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_labiodental': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_coronal': {844: 1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_anterior': {844: 1.0, 845: 0.0, 846: 0.0, 847: 0.0},\n",
       " 'Prod_distributed': {844: -1.0, 845: 0.0, 846: 0.0, 847: 0.0},\n",
       " 'Prod_strident': {844: 1.0, 845: 0.0, 846: 0.0, 847: 0.0},\n",
       " 'Prod_lateral': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Prod_dorsal': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_high': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Prod_low': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Prod_front': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Prod_back': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Prod_tense': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Prod_lax': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Prod_vowel': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Prod_consonant': {844: 1.0, 845: 1.0, 846: -1.0, 847: 1.0},\n",
       " 'Prod_diphthong': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Prod_monophthong': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Prod_velar': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_alveolar': {844: 1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_post-alveolar': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_dental': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_palatal': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_glottal': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_stop': {844: -1.0, 845: 1.0, 846: 0.0, 847: 1.0},\n",
       " 'Prod_fricative': {844: 1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_affricate': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_glide': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Prod_Place': {844: 'alveolar',\n",
       "  845: 'bilabial',\n",
       "  846: 'vowel',\n",
       "  847: 'bilabial'},\n",
       " 'Prod_Manner': {844: 'fricative', 845: 'stop', 846: 'vowel', 847: 'stop'},\n",
       " 'Prod_Place_N': {844: 4.0, 845: 1.0, 846: 0.0, 847: 1.0},\n",
       " 'Prod_Manner_N': {844: 4.0, 845: 1.0, 846: 0.0, 847: 1.0},\n",
       " 'Prod_Height': {844: 'consonant',\n",
       "  845: 'consonant',\n",
       "  846: 'high',\n",
       "  847: 'consonant'},\n",
       " 'Prod_Frontness': {844: 'consonant',\n",
       "  845: 'consonant',\n",
       "  846: 'back',\n",
       "  847: 'consonant'},\n",
       " 'Prod_Height_N': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Prod_Frontness_N': {844: 0.0, 845: 0.0, 846: 3.0, 847: 0.0},\n",
       " 'Target_syllabic': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_consonantal': {844: 1.0, 845: 1.0, 846: -1.0, 847: 1.0},\n",
       " 'Target_sonorant': {844: -1.0, 845: -1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_continuant': {844: 1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_delayed release': {844: 1.0, 845: -1.0, 846: 0.0, 847: 0.0},\n",
       " 'Target_approximant': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_tap': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Target_nasal': {844: -1.0, 845: -1.0, 846: -1.0, 847: 1.0},\n",
       " 'Target_voice': {844: -1.0, 845: -1.0, 846: 1.0, 847: 1.0},\n",
       " 'Target_spread gl': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Target_constr gl': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Target_labial': {844: -1.0, 845: 1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_round': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_labiodental': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Target_coronal': {844: 1.0, 845: -1.0, 846: -1.0, 847: 1.0},\n",
       " 'Target_anterior': {844: 1.0, 845: 0.0, 846: 0.0, 847: 1.0},\n",
       " 'Target_distributed': {844: -1.0, 845: 0.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_strident': {844: 1.0, 845: 0.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_lateral': {844: -1.0, 845: -1.0, 846: -1.0, 847: -1.0},\n",
       " 'Target_dorsal': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_high': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Target_low': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Target_front': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Target_back': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Target_tense': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Target_lax': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Target_vowel': {844: -1.0, 845: -1.0, 846: 1.0, 847: -1.0},\n",
       " 'Target_consonant': {844: 1.0, 845: 1.0, 846: -1.0, 847: 1.0},\n",
       " 'Target_diphthong': {844: 0.0, 845: 0.0, 846: -1.0, 847: 0.0},\n",
       " 'Target_monophthong': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Target_velar': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_alveolar': {844: 1.0, 845: -1.0, 846: 0.0, 847: 1.0},\n",
       " 'Target_post-alveolar': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_dental': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_palatal': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_glottal': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_stop': {844: -1.0, 845: 1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_fricative': {844: 1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_affricate': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_glide': {844: -1.0, 845: -1.0, 846: 0.0, 847: -1.0},\n",
       " 'Target_Place': {844: 'alveolar',\n",
       "  845: 'bilabial',\n",
       "  846: 'vowel',\n",
       "  847: 'alveolar'},\n",
       " 'Target_Manner': {844: 'fricative', 845: 'stop', 846: 'vowel', 847: 'nasal'},\n",
       " 'Target_Place_N': {844: 4.0, 845: 1.0, 846: 0.0, 847: 4.0},\n",
       " 'Target_Manner_N': {844: 4.0, 845: 1.0, 846: 0.0, 847: 2.0},\n",
       " 'Target_Height': {844: 'consonant',\n",
       "  845: 'consonant',\n",
       "  846: 'high',\n",
       "  847: 'consonant'},\n",
       " 'Target_Frontness': {844: 'consonant',\n",
       "  845: 'consonant',\n",
       "  846: 'back',\n",
       "  847: 'consonant'},\n",
       " 'Target_Height_N': {844: 0.0, 845: 0.0, 846: 1.0, 847: 0.0},\n",
       " 'Target_Frontness_N': {844: 0.0, 845: 0.0, 846: 3.0, 847: 0.0},\n",
       " 'Phon_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 0.0},\n",
       " 'Voicing_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 0.0},\n",
       " 'Place_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 0.0},\n",
       " 'Manner_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 0.0},\n",
       " 'Height_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Frontness_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Tenseness_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'Roundness_Acc': {844: 1.0, 845: 1.0, 846: 1.0, 847: 1.0},\n",
       " 'wab1_aq': {844: 64.7, 845: 64.7, 846: 64.7, 847: 64.7},\n",
       " 'wab1_nwf_total': {844: 4.1, 845: 4.1, 846: 4.1, 847: 4.1},\n",
       " 'Session_Type': {844: 'Baseline',\n",
       "  845: 'Baseline',\n",
       "  846: 'Baseline',\n",
       "  847: 'Baseline'},\n",
       " 'wabaq_start': {844: '61-70', 845: '61-70', 846: '61-70', 847: '61-70'},\n",
       " 'Target_Word_IPA': {844: 'spun', 845: 'spun', 846: 'spun', 847: 'spun'},\n",
       " 'Prod_Word_IPA': {844: 'spup', 845: 'spup', 846: 'spup', 847: 'spup'},\n",
       " 'Prod_N_Tot_Phonemes': {844: 4, 845: 4, 846: 4, 847: 4},\n",
       " 'Prod_Phoneme_IPA': {844: 's', 845: 'p', 846: 'u', 847: 'p'},\n",
       " 'Target_Phoneme_IPA': {844: 's', 845: 'p', 846: 'u', 847: 'n'}}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing center to make sure functions worked correctly in identifying the phonological process\n",
    "dfShort.iloc[844:848].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PVM Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted gliding\n",
    "# Gliding: When /r/ or /l/ are produced as a /w/ or /j/, such as “wabbit\" for \"rabbit\" or \"yeyow\" for \"yellow”)\n",
    "# 1 = yes; 0 = no\n",
    "df['gliding'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Manner_Acc'] == 0\n",
    "        and x['Target_approximant'] == 1\n",
    "        and x['Prod_glide'] == 1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted stopping\n",
    "# Stopping: When a fricative (e.g., /f/ or /s/) or affricate (/ʧ/ or /ʤ/) is substituted with a stop consonant, such as “pan\" for \"fan\" or \"dump for \"jump”)\n",
    "# 1 = yes; 0 = no\n",
    "df['stopping'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if x['Manner_Acc'] == 0\n",
    "            and (\n",
    "                x['Target_affricate'] == 1 \n",
    "                or \n",
    "                x['Target_fricative'] == 1\n",
    "                )\n",
    "            and x['Prod_stop'] == 1\n",
    "            else \n",
    "            0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted affrication\n",
    "# Affrication: When a nonaffricate is replaced with an affricate, such as “joor\" for \"door” \n",
    "# 1 = yes; 0 = no\n",
    "df['affrication'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Manner_Acc'] == 0\n",
    "        and x['Prod_affricate'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted deaffrication\n",
    "# Deaffrication: When an affricate is replaced with a stop or fricative, such as “ships” for “chips”\n",
    "# 1 = yes; 0 = no\n",
    "df['deaffrication'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if x['Manner_Acc'] == 0\n",
    "            and x['Target_affricate'] == 1 \n",
    "            and (\n",
    "                x['Prod_stop'] == 1\n",
    "                or\n",
    "                x['Prod_fricative'] == 1\n",
    "                )\n",
    "            else \n",
    "            0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted denasalization\n",
    "# Denasalization: When a nasal consonant changes to a non-nasal consonant, such as “doze” for “nose”\n",
    "# 1 = yes; 0 = no\n",
    "df['denasalization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if x['Manner_Acc'] == 0\n",
    "            and x['Place_Acc'] == 1\n",
    "            and x['Target_nasal'] == 1\n",
    "            else \n",
    "            0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted nasalization\n",
    "# Nasalization: When a non-nasal consonant changes to a nasal consonant, such as \"nose\" for \"doze”\n",
    "# 1 = yes; 0 = no\n",
    "df['nasalization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if x['Manner_Acc'] == 0\n",
    "            and x['Place_Acc'] == 1\n",
    "            and x['Prod_nasal'] == 1\n",
    "            else \n",
    "            0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted backing\n",
    "# Backing: When sounds produced forward in the mouth are substituted with sounds produced farther back in the mouth; e.g., alveolar for velar, such as “got” for “dot”\n",
    "# Note: Only accounts for when consonants replace consonants or vowels replace vowels. Not consonant becomes vowel or vice versa.\n",
    "# 1 = yes; 0 = no\n",
    "df['backing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if \n",
    "                (x['Target_vowel'] == 1\n",
    "                and x['Prod_vowel'] == 1\n",
    "                and x['Target_front'] == 1\n",
    "                and x['Prod_front'] == -1)\n",
    "            or\n",
    "                (x['Target_vowel'] == -1\n",
    "                and x['Prod_vowel'] == -1\n",
    "                and x['Target_Place_N'] < x['Prod_Place_N'])\n",
    "            else \n",
    "                0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted fronting\n",
    "# Fronting: When sounds produced in the backward in the mouth are substituted with sounds produced more forward in the mouth; e.g., alveolar for bilabial, such as \"bot\" for \"dot”\n",
    "# Note: Only accounts for when consonants replace consonants or vowels replace vowels. Not consonant becomes vowel or vice versa.\n",
    "# 1 = yes; 0 = no\n",
    "df['fronting'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "            1 \n",
    "            if \n",
    "                (x['Target_vowel'] == 1\n",
    "                and x['Prod_vowel'] == 1\n",
    "                and x['Target_back'] == 1\n",
    "                and x['Prod_back'] == -1)\n",
    "            or\n",
    "                (x['Target_vowel'] == -1\n",
    "                and x['Prod_vowel'] == -1\n",
    "                and x['Target_Place_N'] > x['Prod_Place_N'])\n",
    "            else \n",
    "                0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted alveolarization\n",
    "# Alveolarization: When a nonalveolar sound is substituted with an alveolar sound, such as “tu\" for \"shoe”\n",
    "# 1 = yes; 0 = no\n",
    "df['alveolarization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_alveolar'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted labialization\n",
    "# Labialization: When a non-bilabial sound is replaced with a bilabial sound, such as “pie\" for \"tie”\n",
    "# 1 = yes; 0 = no\n",
    "df['labialization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_labial'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted velarization\n",
    "# Velarization: When a non-velar sound is replaced with a velar sound, such as “kite” for “light”\n",
    "# 1 = yes; 0 = no\n",
    "df['velarization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_velar'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted post-alveolarization\n",
    "# Post-alveolarization: When a non-post-alveolar sound is replaced with a post-alveolar sound, such as “chair” for “care\n",
    "# 1 = yes; 0 = no\n",
    "df['post-alveolarization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_post-alveolar'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted dentalization\n",
    "# Dentalization: When a non-dental sound is replaced with a dental sound, such as “teeth” for “thief”\n",
    "# 1 = yes; 0 = no\n",
    "df['dentalization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_dental'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted palatalization\n",
    "# Palatalization: When a non-palatal sound is replaced with a palatal sound, such as “year” for “rear”\n",
    "# 1 = yes; 0 = no\n",
    "df['palatalization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_palatal'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted glottalization\n",
    "# Glottalization: When a non-glottal sound is replaced with a glottal sound, such as “here” for “fear”\n",
    "# 1 = yes; 0 = no\n",
    "df['glottalization'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Place_Acc'] == 0\n",
    "        and x['Prod_glottal'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted devoicing\n",
    "# Devoicing: When a voiced production is substituted for a voiceless production, such as “pin” for “bin”\n",
    "# 1 = yes; 0 = no\n",
    "df['devoicing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Voicing_Acc'] == 0\n",
    "        and x['Prod_voice'] == -1\n",
    "        and x['Target_vowel'] == -1\n",
    "        and x['Prod_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted voicing\n",
    "# Voicing: When a voiceless production is substituted for a voiced production, such as “bin” for “pin”\n",
    "# 1 = yes; 0 = no\n",
    "df['voicing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Voicing_Acc'] == 0\n",
    "        and x['Prod_voice'] == 1\n",
    "        and x['Target_vowel'] == -1\n",
    "        and x['Prod_vowel'] == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted prevocalic voicing\n",
    "# Prevocalic Voicing: When a voiceless consonant at the preceding a vowel in a syllable like /k/ or /f/ is substituted with a voiced consonant like /g/ or /v/, such as “gup” for \"cup”\n",
    "# 1 = yes; 0 = no\n",
    "df['prevocalic_voicing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Voicing_Acc'] == 0\n",
    "        and x['Target_Syll_Env'] == '#_V'\n",
    "        and x['Prod_vowel'] == -1\n",
    "        and x['Prod_voice'] == 1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted postvocalic voicing\n",
    "# Postvocalic Voicing: When a voiceless consonant following a vowel in a syllable like /k/ or /f/ is substituted with a voiced consonant like /g/ or /v/, such as “pod” for \"pot”\n",
    "# 1 = yes; 0 = no\n",
    "df['postvocalic_voicing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Voicing_Acc'] == 0\n",
    "        and x['Target_Syll_Env'] == 'V_#'\n",
    "        and x['Prod_vowel'] == -1\n",
    "        and x['Prod_voice'] == 1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted final consonant devoicing\n",
    "# Final Consonant Devoicing: When a voiced consonant at the end of a word like /b/ or /d/ is substituted with a voiceless consonant like /p/ or /t/, such as \"pick\" for \"pig”\n",
    "# 1 = yes; 0 = no\n",
    "df['final_consonant_devoicing'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Voicing_Acc'] == 0\n",
    "        and '_#' in x['Target_Syll_Env']\n",
    "        and x['Prod_vowel'] == -1\n",
    "        and x['Prod_voice'] == 1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted final consonant deletion\n",
    "# Final Consonant Deletion: When the final consonant in a word is left off, such as “toe” for ”toad”\n",
    "# 1 = yes; 0 = no\n",
    "df['final_consonant_deletion'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Prod_Last_Phon'] == 1\n",
    "        and x['Target_Word_Pos'].find('_#') == -1  \n",
    "        and x['Target_Word_Pos'].find('addition') == -1\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted initial consonant deletion\n",
    "# Initial Consonant Deletion: When the initial consonant in a word is left off, such as “ode” for ”toad”\n",
    "# 1 = yes; 0 = no\n",
    "df['initial_consonant_deletion'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if x['Prod_Phon_N'] == 1\n",
    "        and x['Phon_Acc'] == 0\n",
    "        and x['Prod_Phoneme_ID'] == x['Target_Next_Phon']\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted epenthesis\n",
    "# Epenthesis: When an extra sound is added to a word, such as “bu-lue\" for \"blue”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "df['epenthesis'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1 \n",
    "        if len(x['Prod_Word_IPA']) > len(x['Target_Word_IPA'])\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column to calculate the total number of extra phonemes produced by the participant\n",
    "df['Tot_Additions'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        len(x['Prod_Word_IPA']) - len(x['Target_Word_IPA'])\n",
    "        if len(x['Prod_Word_IPA']) > len(x['Target_Word_IPA'])\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column to calculate the total number of missing phonemes from the production based on the target\n",
    "df['Tot_Deletions'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        len(x['Target_Word_IPA']) - len(x['Prod_Word_IPA'])\n",
    "        if len(x['Prod_Word_IPA']) < len(x['Target_Word_IPA'])\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted assimilation\n",
    "# Assimilation: When a consonant sound starts to sound like another sound in the word, such as “bub\" for \"bus”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "df['Target_Word_IPA']=df['Target_Word_IPA'].astype('str')\n",
    "df['Prod_Word_IPA']=df['Prod_Word_IPA'].astype('str')\n",
    "df['Target_Phoneme_IPA']=df['Target_Phoneme_IPA'].astype('str')\n",
    "\n",
    "df['assimilation'] = (\n",
    "    df\n",
    "    .apply(\n",
    "        lambda x: \n",
    "        1\n",
    "        if (\n",
    "            x['Target_Word_IPA'].count(x['Target_Phoneme_IPA']) <\n",
    "            x['Prod_Word_IPA'].count(x['Target_Phoneme_IPA'])\n",
    "        )\n",
    "        else \n",
    "        0, \n",
    "        axis=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted postvocalic assimilation\n",
    "# Postvocalic Assimilation: When a consonant borrows features from a vowel that follows it in the word production (e.g., becomes more fronted or backed due to frontness of the vowel), such as “school” for “spool”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# First, need to determine if the target was a consonant using the 'Target_consonantal' column\n",
    "# And if it was produced in error based on the 'Phon_Acc' column\n",
    "# And if its expected to have a vowel following it based on the 'Target_Syll_Env' column (C_V, #_V, or V_V)\n",
    "\n",
    "# Then, need to determine if the produced consonant has any features that match the following target vowel based on the vowel's height and frontness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted prevocalic assimilation\n",
    "# Prevocalic Assimilation: When a consonant borrows features from a vowel that precedes it in the word production (e.g., becomes more fronted or backed due to frontness of the vowel), such as “leap for “leak”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# First, need to determine if the target was a consonant using the 'Target_consonantal' column\n",
    "# And if it was produced in error based on the 'Phon_Acc' column\n",
    "# And if its expected to have a vowel preceding it based on the 'Target_Syll_Env' column (V_C, V_#, or V_V)\n",
    "\n",
    "# Then, need to determine if the produced consonant has any features that match the preceding target vowel based on the vowel's height and frontness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted coalescence\n",
    "# Coalescence: When two phonemes are substituted with a different phoneme that still has similar features, such as “fort” for “sport”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# Would need to see if target was produced inaccurately and if preceding or succeeding sound is deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted reduplication\n",
    "# Reduplication: When a complete or incomplete syllable is repeated, such as “baba\" for \"battle”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# Not sure our current dataset could do this\n",
    "# Would need to identify syllable boundaries for each word first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted cluster reduction\n",
    "# Cluster Reduction: When a consonant cluster is reduced to a single consonant, such as “soon” for “spoon”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# First need to determine if target is a part of a cluster\n",
    "# Then need to determine if the target was deleted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted weak syllable deletion\n",
    "# Weak Syllable Deletion: When the weak syllable in a word is deleted, such as “nana\" for \"banana”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# Not sure if we can do this with the way the data is currently set up. \n",
    "# Would need to identify strong an weak syllables for each word, then tie those syllables to the phonemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted anticipation\n",
    "# Anticipation: When a speech sound that occurs later in a word/sentence is produced earlier, such as “cork” for “take my bike”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# Would need to identify each word based on its collection of sounds \n",
    "# (e.g., fork would be [10,30,2,13], cork would be [13,20,2,13])\n",
    "# Then, you would need to determine if one of the sounds was repeated (e.g., /k/ is expected to occur once, but it occurs twice)\n",
    "# And whether the repeated sound happens earlier in the list then expected (position 1, when it should be in position 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted preservation\n",
    "# Preservation: When a speech sound that occurs earlier in a word/sentence is produced later, such as “nine” for “knife”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# Would need to identify each word based on its collection of sounds \n",
    "# (e.g., knife would be [16,40,10], nine would be [16,40,16])\n",
    "# Then, you would need to determine if one of the sounds was repeated (e.g., /n/ is expected to occur once, but it occurs twice)\n",
    "# And whether the repeated sound happens later in the list then expected (position 3, when it should be in position 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted a shift\n",
    "# Shift: When a speech sound that is supposed to occur in one part of the word/sentence is produced at a different part of the word/sentence, such as “poons” for “spoon”\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "def identify_shift(row):\n",
    "    target_phonemes = list(row['Target_Word_IPA'])  # Assuming IPA representation is a string where each character represents a phoneme\n",
    "    prod_phonemes = list(row['Prod_Word_IPA'])\n",
    "\n",
    "    if row['Phon_Acc'] == 0:  # Check if there is an error in production\n",
    "        target_phoneme = row['Target_Phoneme_IPA']\n",
    "\n",
    "        # Check if the target phoneme appears in the produced word\n",
    "        if target_phoneme in prod_phonemes:\n",
    "            target_position = row['Target_Phoneme_ID']\n",
    "            prod_position = prod_phonemes.index(target_phoneme)\n",
    "\n",
    "            # Check if the target phoneme appears at a different position in the produced word\n",
    "            if target_position != prod_position:\n",
    "                return 1\n",
    "\n",
    "    return 0\n",
    "\n",
    "df['shift'] = df.apply(identify_shift, axis=1)\n",
    "\n",
    "# # Would need to identify each word based on its collection of sounds \n",
    "# (e.g., spoon would be [19,18,38,16], poons would be [18,38,16,19])\n",
    "# Then, would need to see if all sounds that should be present are present regardless of position\n",
    "# Then, would determine whether the order of sounds shifted position, so if +/- 1 position would result in a series of correct positions for more than one sound in the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted an exchange\n",
    "# Exchange: When a sound in one part of a word/sentence trades places with a sound in another part of the word/sentence, such as 'call' for 'lock'\n",
    "# 1 = yes; 0 = no\n",
    "\n",
    "# # Would need to identify each word based on its collection of sounds \n",
    "# (e.g., spoon would be [19,18,38,16], poons would be [18,38,16,19])\n",
    "# Then, would need to see if all sounds that should be present are present regardless of position\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function to determine if change constituted compound word reduction\n",
    "# Compound Word Reduction: When a compound word is reduced to a single root word or syllable, such as “lunch” for “lunchbox”\n",
    "# 1 = yes; 0 = no\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prod_Word_IPA</th>\n",
       "      <th>Target_Word_IPA</th>\n",
       "      <th>Prod_Phoneme_IPA</th>\n",
       "      <th>Target_Phoneme_IPA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>rʌb</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>rʌbɚn</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>rʌbɚn</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>n</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>rʌbɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>rʌbɚl</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>l</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>rʌbɚnəʔ</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>rʌbɚnəʔ</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>ʔ</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>rʌbɚn</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>ɐf</td>\n",
       "      <td>nɐf</td>\n",
       "      <td>f</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>steʔ</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>steʔ</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>ʔ</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>ste</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ste</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>t</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>rʌb</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>rʌbɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>pts</td>\n",
       "      <td>tep</td>\n",
       "      <td>p</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>pts</td>\n",
       "      <td>tep</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>rʌ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>rʌbɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>sefsefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>sefsefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>e</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>ssefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>ssefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>ssefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>ssefti</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>t</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>brʌʃ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʃ</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>resɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>resɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>resɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>kə</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ə</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>sio</td>\n",
       "      <td>kom</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>sioɛn</td>\n",
       "      <td>kom</td>\n",
       "      <td>i</td>\n",
       "      <td>o</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>kəsʌmθɪŋ</td>\n",
       "      <td>spun</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>sup</td>\n",
       "      <td>spun</td>\n",
       "      <td>u</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>sup</td>\n",
       "      <td>spun</td>\n",
       "      <td>p</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>skup</td>\n",
       "      <td>spun</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>kʌr</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>r</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>fɔrk</td>\n",
       "      <td>nɐf</td>\n",
       "      <td>r</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>truθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>r</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>truθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>u</td>\n",
       "      <td>θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1030</th>\n",
       "      <td>buts</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>buts</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>s</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>ər</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>ər</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>res</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>res</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>smɛʧɪz</td>\n",
       "      <td>mæʧəz</td>\n",
       "      <td>s</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>smɛʧɪz</td>\n",
       "      <td>mæʧəz</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>ʧ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>smɛʧɪz</td>\n",
       "      <td>mæʧəz</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1231</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>skruʤɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ʤ</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>skutɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>t</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>sup</td>\n",
       "      <td>spun</td>\n",
       "      <td>u</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>sup</td>\n",
       "      <td>spun</td>\n",
       "      <td>p</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>ə</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>l</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>p</td>\n",
       "      <td>ɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>brʊʧɚtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>brʊʧɚtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>brʊʧɚtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʧ</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>brʊʧɚtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>brʊʃtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>b</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659</th>\n",
       "      <td>brʊʃtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>θ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660</th>\n",
       "      <td>brʊʃtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʃ</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>brʊʃtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1663</th>\n",
       "      <td>brʊʃtiθ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>θ</td>\n",
       "      <td>ʃ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>brʊʃ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʃ</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1681</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1683</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>v</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1685</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>srudrovɚdrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>e</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>s</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1810</th>\n",
       "      <td>sun</td>\n",
       "      <td>spun</td>\n",
       "      <td>n</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1854</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>drɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>drɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>e</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1884</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1885</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>l</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>pepɚklɪ</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>kkʊm</td>\n",
       "      <td>kom</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>v</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>skudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>rʊbɚrʊbɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>r</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>rʊbɚrʊbɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>rʊbɚrʊbɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>rʊbɚrʊbɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2040</th>\n",
       "      <td>gʊdɑkɑrl</td>\n",
       "      <td>bʊk</td>\n",
       "      <td>d</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>mʊkænɪk</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2103</th>\n",
       "      <td>pɛn</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>n</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2106</th>\n",
       "      <td>pɪf</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>f</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>mænɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2197</th>\n",
       "      <td>mænɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2200</th>\n",
       "      <td>æmɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>m</td>\n",
       "      <td>æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2201</th>\n",
       "      <td>æmɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>brʊʃ</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>ʃ</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>leɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>ledɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>ledɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2271</th>\n",
       "      <td>ʤrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>pɛn</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>n</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>skɑʧte</td>\n",
       "      <td>tep</td>\n",
       "      <td>s</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>skɑʧte</td>\n",
       "      <td>tep</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>mæʊʧ</td>\n",
       "      <td>mæʧəz</td>\n",
       "      <td>ʊ</td>\n",
       "      <td>ʧ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>rimot</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2383</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2389</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2412</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2414</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>kʌp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>tɐstikom</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>t</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2514</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>u</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2515</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2516</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2517</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>v</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>krudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2534</th>\n",
       "      <td>bɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>æ</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2535</th>\n",
       "      <td>bɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2536</th>\n",
       "      <td>bɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>d</td>\n",
       "      <td>æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>lɑk</td>\n",
       "      <td>lɑk</td>\n",
       "      <td>ʌ</td>\n",
       "      <td>ɑ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>udrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>udrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>ɚhæmɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>h</td>\n",
       "      <td>æ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2662</th>\n",
       "      <td>ɚhæmɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>æ</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2663</th>\n",
       "      <td>ɚhæmɚ</td>\n",
       "      <td>hæmɚ</td>\n",
       "      <td>m</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2678</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>rʌbɚbænd</td>\n",
       "      <td>ə</td>\n",
       "      <td>ʌ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2757</th>\n",
       "      <td>pest</td>\n",
       "      <td>tuθbrəʃ</td>\n",
       "      <td>p</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2783</th>\n",
       "      <td>p</td>\n",
       "      <td>pɛnsəl</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>bɑbipɪn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2882</th>\n",
       "      <td>bɑbipɪn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>bɑbipɪn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>n</td>\n",
       "      <td>ɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>s</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>k</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>u</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>d</td>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>r</td>\n",
       "      <td>ɐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>ɐ</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>sskrudrɐvɚ</td>\n",
       "      <td>skrudrɐvɚ</td>\n",
       "      <td>v</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>pest</td>\n",
       "      <td>tep</td>\n",
       "      <td>p</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2958</th>\n",
       "      <td>pest</td>\n",
       "      <td>tep</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>pestɚ</td>\n",
       "      <td>tep</td>\n",
       "      <td>p</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>pestɚ</td>\n",
       "      <td>tep</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2979</th>\n",
       "      <td>ʧɑrʤ</td>\n",
       "      <td>mæʧəz</td>\n",
       "      <td>r</td>\n",
       "      <td>ʧ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3013</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3036</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3037</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>ɚ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3039</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>l</td>\n",
       "      <td>k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3040</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3041</th>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>p</td>\n",
       "      <td>ɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>i</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɚ</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>seftiklɪp</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>seftiklɪp</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>l</td>\n",
       "      <td>ɪ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>seftipɛn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>i</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3188</th>\n",
       "      <td>seftipɛn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>p</td>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3189</th>\n",
       "      <td>seftipɛn</td>\n",
       "      <td>seftipɪn</td>\n",
       "      <td>ɛ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3218</th>\n",
       "      <td>əresɚ</td>\n",
       "      <td>əresɚ</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>ə</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>k</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>klɪp</td>\n",
       "      <td>pepɚklɪp</td>\n",
       "      <td>ɪ</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Prod_Word_IPA Target_Word_IPA Prod_Phoneme_IPA Target_Phoneme_IPA\n",
       "72                ə           əresɚ                i                  ə\n",
       "74              rʌb           əresɚ                ʌ                  r\n",
       "77            rʌbɚn           əresɚ                ʌ                  r\n",
       "80            rʌbɚn           əresɚ                n                  ɚ\n",
       "82             rʌbɚ           əresɚ                ʌ                  r\n",
       "194           rʌbɚl        rʌbɚbænd                l                  b\n",
       "203         rʌbɚnəʔ        rʌbɚbænd                n                  b\n",
       "205         rʌbɚnəʔ        rʌbɚbænd                ʔ                  n\n",
       "210           rʌbɚn        rʌbɚbænd                n                  b\n",
       "262              ɐf             nɐf                f                  ɐ\n",
       "289            steʔ        seftipɪn                t                  e\n",
       "291            steʔ        seftipɪn                ʔ                  t\n",
       "293             ste        seftipɪn                t                  e\n",
       "296             ste        seftipɪn                t                  e\n",
       "338             rʌb           əresɚ                ʌ                  r\n",
       "341            rʌbɚ           əresɚ                ʌ                  r\n",
       "428             pts             tep                p                  t\n",
       "430             pts             tep                s                  p\n",
       "483              rʌ           əresɚ                ʌ                  r\n",
       "485            rʌbɚ           əresɚ                ɚ                  r\n",
       "603        sefsefti        seftipɪn                s                  t\n",
       "604        sefsefti        seftipɪn                e                  i\n",
       "617          ssefti        seftipɪn                s                  e\n",
       "618          ssefti        seftipɪn                e                  f\n",
       "619          ssefti        seftipɪn                f                  t\n",
       "620          ssefti        seftipɪn                t                  i\n",
       "644            brʌʃ         tuθbrəʃ                ʃ                  b\n",
       "676               ə           əresɚ                i                  ə\n",
       "677               ə           əresɚ                i                  ə\n",
       "682               ə           əresɚ                i                  ə\n",
       "695            resɚ           əresɚ                e                  r\n",
       "696            resɚ           əresɚ                s                  e\n",
       "697            resɚ           əresɚ                ɚ                  s\n",
       "711              kə       skrudrɐvɚ                ə                  k\n",
       "784             sio             kom                i                  o\n",
       "787           sioɛn             kom                i                  o\n",
       "830        kəsʌmθɪŋ            spun                k                  s\n",
       "842             sup            spun                u                  p\n",
       "843             sup            spun                p                  u\n",
       "849            skup            spun                k                  p\n",
       "913             kʌr             bʊk                r                  k\n",
       "946            fɔrk             nɐf                r                  f\n",
       "1017           truθ         tuθbrəʃ                r                  u\n",
       "1018           truθ         tuθbrəʃ                u                  θ\n",
       "1030           buts         tuθbrəʃ                b                  t\n",
       "1033           buts         tuθbrəʃ                s                  b\n",
       "1047              ə           əresɚ                i                  ə\n",
       "1048             ər           əresɚ                i                  ə\n",
       "1050             ər           əresɚ                i                  ə\n",
       "1053            res           əresɚ                e                  r\n",
       "1054            res           əresɚ                s                  e\n",
       "1075      skrudrɐvɚ       skrudrɐvɚ                d                  ɐ\n",
       "1076      skrudrɐvɚ       skrudrɐvɚ                r                  v\n",
       "1077      skrudrɐvɚ       skrudrɐvɚ                ɐ                  ɚ\n",
       "1168         smɛʧɪz           mæʧəz                s                  m\n",
       "1170         smɛʧɪz           mæʧəz                ɛ                  ʧ\n",
       "1172         smɛʧɪz           mæʧəz                ɪ                  z\n",
       "1230              ə           əresɚ                i                  ə\n",
       "1231              ə           əresɚ                i                  ə\n",
       "1232              ə           əresɚ                i                  ə\n",
       "1233          əresɚ           əresɚ                ɪ                  ə\n",
       "1287         skruʤɚ       skrudrɐvɚ                ʤ                  u\n",
       "1292          skutɚ       skrudrɐvɚ                t                  u\n",
       "1322            sup            spun                u                  p\n",
       "1323            sup            spun                p                  u\n",
       "1559              ə           əresɚ                ɪ                  ə\n",
       "1587       pepɚklɪp        pepɚklɪp                e                  p\n",
       "1588       pepɚklɪp        pepɚklɪp                p                  e\n",
       "1589       pepɚklɪp        pepɚklɪp                ɚ                  p\n",
       "1590       pepɚklɪp        pepɚklɪp                k                  ɚ\n",
       "1591       pepɚklɪp        pepɚklɪp                l                  k\n",
       "1592       pepɚklɪp        pepɚklɪp                ɪ                  l\n",
       "1593       pepɚklɪp        pepɚklɪp                p                  ɪ\n",
       "1649       brʊʧɚtiθ         tuθbrəʃ                b                  t\n",
       "1651       brʊʧɚtiθ         tuθbrəʃ                ʊ                  θ\n",
       "1652       brʊʧɚtiθ         tuθbrəʃ                ʧ                  b\n",
       "1653       brʊʧɚtiθ         tuθbrəʃ                ɚ                  r\n",
       "1657        brʊʃtiθ         tuθbrəʃ                b                  t\n",
       "1659        brʊʃtiθ         tuθbrəʃ                ʊ                  θ\n",
       "1660        brʊʃtiθ         tuθbrəʃ                ʃ                  b\n",
       "1661        brʊʃtiθ         tuθbrəʃ                t                  r\n",
       "1663        brʊʃtiθ         tuθbrəʃ                θ                  ʃ\n",
       "1667           brʊʃ         tuθbrəʃ                ʃ                  b\n",
       "1668          əresɚ           əresɚ                ɛ                  ə\n",
       "1680  srudrovɚdrɐvɚ       skrudrɐvɚ                u                  r\n",
       "1681  srudrovɚdrɐvɚ       skrudrɐvɚ                d                  u\n",
       "1682  srudrovɚdrɐvɚ       skrudrɐvɚ                r                  d\n",
       "1683  srudrovɚdrɐvɚ       skrudrɐvɚ                o                  r\n",
       "1684  srudrovɚdrɐvɚ       skrudrɐvɚ                v                  ɐ\n",
       "1685  srudrovɚdrɐvɚ       skrudrɐvɚ                ɚ                  v\n",
       "1686  srudrovɚdrɐvɚ       skrudrɐvɚ                d                  ɚ\n",
       "1767          əresɚ           əresɚ                r                  ə\n",
       "1768          əresɚ           əresɚ                e                  r\n",
       "1769          əresɚ           əresɚ                s                  e\n",
       "1770          əresɚ           əresɚ                ɚ                  s\n",
       "1810            sun            spun                n                  u\n",
       "1854          əresɚ           əresɚ                ʊ                  ə\n",
       "1876          drɐvɚ       skrudrɐvɚ                ɐ                  r\n",
       "1878          drɐvɚ       skrudrɐvɚ                ɚ                  d\n",
       "1881        pepɚklɪ        pepɚklɪp                e                  p\n",
       "1882        pepɚklɪ        pepɚklɪp                p                  e\n",
       "1883        pepɚklɪ        pepɚklɪp                ɚ                  p\n",
       "1884        pepɚklɪ        pepɚklɪp                k                  ɚ\n",
       "1885        pepɚklɪ        pepɚklɪp                l                  k\n",
       "1886        pepɚklɪ        pepɚklɪp                ɪ                  l\n",
       "1892           kkʊm             kom                ʊ                  m\n",
       "1963       skudrɐvɚ       skrudrɐvɚ                u                  r\n",
       "1964       skudrɐvɚ       skrudrɐvɚ                d                  u\n",
       "1965       skudrɐvɚ       skrudrɐvɚ                r                  d\n",
       "1966       skudrɐvɚ       skrudrɐvɚ                ɐ                  r\n",
       "1967       skudrɐvɚ       skrudrɐvɚ                v                  ɐ\n",
       "1968       skudrɐvɚ       skrudrɐvɚ                ɚ                  v\n",
       "2000   rʊbɚrʊbɚbænd        rʌbɚbænd                r                  b\n",
       "2001   rʊbɚrʊbɚbænd        rʌbɚbænd                ʊ                  æ\n",
       "2002   rʊbɚrʊbɚbænd        rʌbɚbænd                b                  n\n",
       "2003   rʊbɚrʊbɚbænd        rʌbɚbænd                ɚ                  d\n",
       "2040       gʊdɑkɑrl             bʊk                d                  k\n",
       "2093        mʊkænɪk       skrudrɐvɚ                ʊ                  k\n",
       "2103            pɛn        pepɚklɪp                n                  p\n",
       "2106            pɪf        pepɚklɪp                f                  p\n",
       "2117           klɪp        pepɚklɪp                k                  p\n",
       "2119           klɪp        pepɚklɪp                ɪ                  p\n",
       "2193           mænɚ            hæmɚ                n                  m\n",
       "2197           mænɚ            hæmɚ                n                  m\n",
       "2200            æmɚ            hæmɚ                m                  æ\n",
       "2201            æmɚ            hæmɚ                ɚ                  m\n",
       "2244           brʊʃ         tuθbrəʃ                ʃ                  b\n",
       "2252            leɚ           əresɚ                ɚ                  e\n",
       "2255           ledɚ           əresɚ                d                  e\n",
       "2259           ledɚ           əresɚ                d                  e\n",
       "2271          ʤrɐvɚ       skrudrɐvɚ                ɐ                  r\n",
       "2287            pɛn        pepɚklɪp                n                  p\n",
       "2312         skɑʧte             tep                s                  t\n",
       "2313         skɑʧte             tep                k                  e\n",
       "2320           mæʊʧ           mæʧəz                ʊ                  ʧ\n",
       "2375          rimot           əresɚ                i                  r\n",
       "2379          əresɚ           əresɚ                i                  ə\n",
       "2383          əresɚ           əresɚ                i                  ə\n",
       "2389          əresɚ           əresɚ                ɐ                  e\n",
       "2412           klɪp        pepɚklɪp                k                  p\n",
       "2414           klɪp        pepɚklɪp                ɪ                  p\n",
       "2416            kʌp        pepɚklɪp                k                  p\n",
       "2469       tɐstikom        seftipɪn                t                  s\n",
       "2496          əresɚ           əresɚ                i                  ə\n",
       "2513       krudrɐvɚ       skrudrɐvɚ                r                  k\n",
       "2514       krudrɐvɚ       skrudrɐvɚ                u                  r\n",
       "2515       krudrɐvɚ       skrudrɐvɚ                d                  u\n",
       "2516       krudrɐvɚ       skrudrɐvɚ                r                  d\n",
       "2517       krudrɐvɚ       skrudrɐvɚ                ɐ                  r\n",
       "2518       krudrɐvɚ       skrudrɐvɚ                v                  ɐ\n",
       "2519       krudrɐvɚ       skrudrɐvɚ                ɚ                  v\n",
       "2534         bɚbænd        rʌbɚbænd                æ                  ɚ\n",
       "2535         bɚbænd        rʌbɚbænd                n                  b\n",
       "2536         bɚbænd        rʌbɚbænd                d                  æ\n",
       "2583          əresɚ           əresɚ                i                  ə\n",
       "2588            lɑk             lɑk                ʌ                  ɑ\n",
       "2593         udrɐvɚ       skrudrɐvɚ                ɐ                  u\n",
       "2594         udrɐvɚ       skrudrɐvɚ                v                  d\n",
       "2661          ɚhæmɚ            hæmɚ                h                  æ\n",
       "2662          ɚhæmɚ            hæmɚ                æ                  m\n",
       "2663          ɚhæmɚ            hæmɚ                m                  ɚ\n",
       "2678          əresɚ           əresɚ                ɛ                  ə\n",
       "2703       rʌbɚbænd        rʌbɚbænd                ə                  ʌ\n",
       "2757           pest         tuθbrəʃ                p                  t\n",
       "2783              p          pɛnsəl                t                  p\n",
       "2881        bɑbipɪn        seftipɪn                p                  i\n",
       "2882        bɑbipɪn        seftipɪn                ɪ                  p\n",
       "2883        bɑbipɪn        seftipɪn                n                  ɪ\n",
       "2904     sskrudrɐvɚ       skrudrɐvɚ                s                  k\n",
       "2905     sskrudrɐvɚ       skrudrɐvɚ                k                  r\n",
       "2906     sskrudrɐvɚ       skrudrɐvɚ                r                  u\n",
       "2907     sskrudrɐvɚ       skrudrɐvɚ                u                  d\n",
       "2908     sskrudrɐvɚ       skrudrɐvɚ                d                  r\n",
       "2909     sskrudrɐvɚ       skrudrɐvɚ                r                  ɐ\n",
       "2910     sskrudrɐvɚ       skrudrɐvɚ                ɐ                  v\n",
       "2911     sskrudrɐvɚ       skrudrɐvɚ                v                  ɚ\n",
       "2956           pest             tep                p                  t\n",
       "2958           pest             tep                s                  p\n",
       "2960          pestɚ             tep                p                  t\n",
       "2962          pestɚ             tep                s                  p\n",
       "2979           ʧɑrʤ           mæʧəz                r                  ʧ\n",
       "3013          əresɚ           əresɚ                ɪ                  ə\n",
       "3036       pepɚklɪp        pepɚklɪp                p                  e\n",
       "3037       pepɚklɪp        pepɚklɪp                ɚ                  p\n",
       "3038       pepɚklɪp        pepɚklɪp                k                  ɚ\n",
       "3039       pepɚklɪp        pepɚklɪp                l                  k\n",
       "3040       pepɚklɪp        pepɚklɪp                ɪ                  l\n",
       "3041       pepɚklɪp        pepɚklɪp                p                  ɪ\n",
       "3095          əresɚ           əresɚ                i                  ə\n",
       "3098          əresɚ           əresɚ                ɚ                  s\n",
       "3180      seftiklɪp        seftipɪn                k                  p\n",
       "3181      seftiklɪp        seftipɪn                l                  ɪ\n",
       "3187       seftipɛn        seftipɪn                i                  t\n",
       "3188       seftipɛn        seftipɪn                p                  i\n",
       "3189       seftipɛn        seftipɪn                ɛ                  p\n",
       "3218          əresɚ           əresɚ                ɪ                  ə\n",
       "3251           klɪp        pepɚklɪp                k                  p\n",
       "3253           klɪp        pepɚklɪp                ɪ                  p"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing center to make sure functions worked correctly in identifying the phonological process\n",
    "df[df['shift']==1][['Prod_Word_IPA','Target_Word_IPA','Prod_Phoneme_IPA', 'Target_Phoneme_IPA']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
